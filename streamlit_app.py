import streamlit as st
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF
import io
import cv2
import numpy as np
import re
import easyocr
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.lib.utils import ImageReader
from streamlit_image_coordinates import streamlit_image_coordinates
from datetime import datetime
import warnings
import json
import os
from pathlib import Path
from collections import deque
import math
from scipy.signal import savgol_filter
warnings.filterwarnings('ignore')

# Import with fallback for streamlit-image-coordinates
try:
    from streamlit_image_coordinates import streamlit_image_coordinates
    HAS_IMAGE_COORDINATES = True
except ImportError:
    HAS_IMAGE_COORDINATES = False
    st.error("streamlit-image-coordinatesãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install streamlit-image-coordinatesã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

st.set_page_config(layout="wide")
st.title("å›³é¢å¸¯ã‚«ãƒƒãƒˆãã‚“ï½œä¸å‹•ç”£å–¶æ¥­ã®å³æˆ¦åŠ›")
APP_VERSION = "v1.7.4"
st.markdown(f"#### ğŸ·ï¸ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {APP_VERSION}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–"""
    defaults = {
        'processed_image': None,
        'original_image': None,
        'preview_image': None,
        'auto_detected_area': None,
        'current_mode': 'auto',
        'manual_coords': [],
        'fill_areas': [],
        'processing_step': 'upload',
        'last_uploaded_file': None,
        'template_image': None,
        'eyedropper_mode': False,
        'property_name': '',
        'property_price': '',
        'selected_color': '#FFFFFF',
        'confirmed_drawing_area': None,
        'learning_data_version': '1.0',
        'recent_predictions': deque(maxlen=10)  # ç›´è¿‘10ä»¶ã®äºˆæ¸¬ã‚’ä¿å­˜
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å…ˆ
LEARNING_DATA_DIR = Path("learning_data")
LEARNING_DATA_FILE = LEARNING_DATA_DIR / "band_detection_data.json"

@st.cache_resource
def get_ocr_reader():
    """EasyOCRãƒªãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
    try:
        with st.spinner("åˆå›èµ·å‹•æ™‚ï¼šAIï¼ˆOCRãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...ï¼ˆæ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰"):
            # Warningã‚’éè¡¨ç¤ºã«ã™ã‚‹
            import logging
            logging.getLogger('easyocr').setLevel(logging.ERROR)
            reader = easyocr.Reader(['ja', 'en'])
        st.success("âœ… AIï¼ˆOCRãƒ¢ãƒ‡ãƒ«ï¼‰ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return reader
    except Exception as e:
        st.error(f"OCRã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚EasyOCRãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚: {e}")
        st.warning("`pip install easyocr` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

def migrate_old_learning_data():
    """å¤ã„å½¢å¼ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„å½¢å¼ã«ç§»è¡Œ"""
    try:
        if not LEARNING_DATA_FILE.exists():
            return
        
        with open(LEARNING_DATA_FILE, 'r') as f:
            data = json.load(f)
        
        # æ—¢ã«æ–°ã—ã„å½¢å¼ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
        if 'learning_records' in data:
            return
        
        # å¤ã„å½¢å¼ã‹ã‚‰æ–°ã—ã„å½¢å¼ã«ç§»è¡Œ
        if 'band_positions' in data and 'image_features' in data:
            st.info("ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„å½¢å¼ã«ç§»è¡Œä¸­...")
            
            new_data = {
                'version': '1.0',
                'learning_records': [],
                'metadata': {
                    'total_records': len(data['band_positions']),
                    'manual_corrections': 0,
                    'auto_detections': len(data['band_positions']),
                    'last_updated': datetime.now().isoformat()
                }
            }
            
            # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„å½¢å¼ã«å¤‰æ›
            for i, (position, features) in enumerate(zip(data['band_positions'], data['image_features'])):
                record = {
                    'id': i + 1,
                    'timestamp': datetime.now().isoformat(),
                    'band_position': position,
                    'image_features': features,
                    'confidence': 0.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‡ªä¿¡åº¦
                    'is_manual_correction': False,  # å¤ã„ãƒ‡ãƒ¼ã‚¿ã¯è‡ªå‹•æ¤œå‡ºã¨ã—ã¦æ‰±ã†
                    'is_positive_example': True
                }
                new_data['learning_records'].append(record)
            
            # æ–°ã—ã„å½¢å¼ã§ä¿å­˜
            with open(LEARNING_DATA_FILE, 'w') as f:
                json.dump(new_data, f, indent=2)
            
            st.success("âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

def init_learning_data():
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–"""
    LEARNING_DATA_DIR.mkdir(exist_ok=True)
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œã‚’è©¦è¡Œ
    migrate_old_learning_data()
    
    if not LEARNING_DATA_FILE.exists():
        with open(LEARNING_DATA_FILE, 'w') as f:
            json.dump({
                'version': '1.0',
                'learning_records': [],
                'metadata': {
                    'total_records': 0,
                    'manual_corrections': 0,
                    'auto_detections': 0,
                    'last_updated': datetime.now().isoformat()
                }
            }, f, indent=2)

def extract_color_features(image: Image.Image, band_area=None):
    """ç”»åƒã‹ã‚‰è‰²ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
    try:
        # RGBã«å¤‰æ›
        rgb_img = image.convert('RGB')
        np_img = np.array(rgb_img)
        
        # è‰²ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¨ˆç®—ï¼ˆå„ãƒãƒ£ãƒ³ãƒãƒ«16ãƒ“ãƒ³ï¼‰
        hist_r = cv2.calcHist([np_img], [0], None, [16], [0, 256]).flatten()
        hist_g = cv2.calcHist([np_img], [1], None, [16], [0, 256]).flatten()
        hist_b = cv2.calcHist([np_img], [2], None, [16], [0, 256]).flatten()
        
        # æ­£è¦åŒ–
        hist_r = hist_r / np.sum(hist_r)
        hist_g = hist_g / np.sum(hist_g)
        hist_b = hist_b / np.sum(hist_b)
        
        # HSVå¤‰æ›ã—ã¦è‰²ç›¸ãƒ»æ˜åº¦ã‚’è¨ˆç®—
        hsv_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2HSV)
        h, s, v = cv2.split(hsv_img)
        
        # å¸¯é ˜åŸŸãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®é ˜åŸŸã®ã¿åˆ†æ
        if band_area:
            x1, y1, x2, y2 = band_area
            h_band = h[y1:y2, x1:x2]
            s_band = s[y1:y2, x1:x2]
            v_band = v[y1:y2, x1:x2]
            
            # å¸¯é ˜åŸŸã®è‰²ç›¸ãƒ»æ˜åº¦ã®çµ±è¨ˆ
            hue_mean = np.mean(h_band)
            hue_std = np.std(h_band)
            value_mean = np.mean(v_band)
            value_std = np.std(v_band)
        else:
            # å…¨ä½“ã®è‰²ç›¸ãƒ»æ˜åº¦ã®çµ±è¨ˆ
            hue_mean = np.mean(h)
            hue_std = np.std(h)
            value_mean = np.mean(v)
            value_std = np.std(v)
        
        return {
            'hist_r': hist_r.tolist(),
            'hist_g': hist_g.tolist(),
            'hist_b': hist_b.tolist(),
            'hue_mean': float(hue_mean),
            'hue_std': float(hue_std),
            'value_mean': float(value_mean),
            'value_std': float(value_std)
        }
    except Exception as e:
        st.error(f"è‰²ç‰¹å¾´é‡ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

def extract_image_features(image: Image.Image, band_area=None):
    """ç”»åƒã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆè‰²ç‰¹å¾´é‡è¿½åŠ ç‰ˆï¼‰"""
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = np.array(image.convert('L'))
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(gray, 50, 150)
        
        # åŸºæœ¬ç‰¹å¾´é‡
        basic_features = {
            'width': image.width,
            'height': image.height,
            'edge_density': np.mean(edges) / 255.0,
            'brightness': np.mean(gray) / 255.0
        }
        
        # è‰²ç‰¹å¾´é‡ã‚’è¿½åŠ 
        color_features = extract_color_features(image, band_area)
        if color_features:
            basic_features.update(color_features)
        
        return basic_features
    except Exception as e:
        st.error(f"ç‰¹å¾´é‡ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

def calculate_similarity(features1, features2):
    """2ã¤ã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    try:
        # åŸºæœ¬ç‰¹å¾´é‡ã®é¡ä¼¼åº¦
        basic_diff = (
            abs(features1['width'] - features2['width']) / max(features1['width'], features2['width']) +
            abs(features1['height'] - features2['height']) / max(features1['height'], features2['height']) +
            abs(features1['edge_density'] - features2['edge_density']) +
            abs(features1['brightness'] - features2['brightness'])
        ) / 4.0
        
        # è‰²ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®é¡ä¼¼åº¦ï¼ˆã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰
        hist_similarity = 0
        if 'hist_r' in features1 and 'hist_r' in features2:
            hist_r_sim = np.dot(features1['hist_r'], features2['hist_r']) / (
                np.linalg.norm(features1['hist_r']) * np.linalg.norm(features2['hist_r']) + 1e-8
            )
            hist_g_sim = np.dot(features1['hist_g'], features2['hist_g']) / (
                np.linalg.norm(features1['hist_g']) * np.linalg.norm(features2['hist_g']) + 1e-8
            )
            hist_b_sim = np.dot(features1['hist_b'], features2['hist_b']) / (
                np.linalg.norm(features1['hist_b']) * np.linalg.norm(features2['hist_b']) + 1e-8
            )
            hist_similarity = (hist_r_sim + hist_g_sim + hist_b_sim) / 3.0
        
        # è‰²ç›¸ãƒ»æ˜åº¦ã®é¡ä¼¼åº¦
        color_similarity = 0
        if 'hue_mean' in features1 and 'hue_mean' in features2:
            hue_diff = abs(features1['hue_mean'] - features2['hue_mean']) / 180.0
            value_diff = abs(features1['value_mean'] - features2['value_mean']) / 255.0
            color_similarity = 1.0 - (hue_diff + value_diff) / 2.0
        
        # ç·åˆé¡ä¼¼åº¦ï¼ˆåŸºæœ¬:è‰²:è‰²ç›¸ = 3:4:3ã®é‡ã¿ï¼‰
        total_similarity = (1.0 - basic_diff) * 0.3 + hist_similarity * 0.4 + color_similarity * 0.3
        
        return total_similarity
    except Exception as e:
        st.error(f"é¡ä¼¼åº¦è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return 0.0

def save_learning_data(band_position, image_features, confidence=0.5, is_manual_correction=False):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆãƒ•ãƒ©ã‚°ãƒ»è‡ªä¿¡åº¦ä»˜ãï¼‰"""
    try:
        LEARNING_DATA_DIR.mkdir(exist_ok=True)
        if LEARNING_DATA_FILE.exists():
            with open(LEARNING_DATA_FILE, 'r') as f:
                data = json.load(f)
        else:
            data = {
                'version': '1.0',
                'learning_records': [],
                'metadata': {
                    'total_records': 0,
                    'manual_corrections': 0,
                    'auto_detections': 0,
                    'last_updated': datetime.now().isoformat()
                }
            }
        
        # æ–°ã—ã„å­¦ç¿’ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
        record = {
            'id': len(data['learning_records']) + 1,
            'timestamp': datetime.now().isoformat(),
            'band_position': band_position,
            'image_features': image_features,
            'confidence': confidence,
            'is_manual_correction': is_manual_correction,
            'is_positive_example': True  # æ­£ä¾‹ã¨ã—ã¦ä¿å­˜
        }
        
        # ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 
        data['learning_records'].append(record)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        data['metadata']['total_records'] = len(data['learning_records'])
        if is_manual_correction:
            data['metadata']['manual_corrections'] += 1
        else:
            data['metadata']['auto_detections'] += 1
        data['metadata']['last_updated'] = datetime.now().isoformat()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        with open(LEARNING_DATA_FILE, 'w') as f:
            json.dump(data, f, indent=2)
        
        # ä»¶æ•°åˆ¶é™ã‚’è‡ªå‹•é©ç”¨ï¼ˆ1,000ä»¶ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        manage_learning_data(1000)
        
        return True
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def predict_band_position(image: Image.Image, use_recent_average=True, min_confidence=0.3):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«å¸¯ä½ç½®ã‚’äºˆæ¸¬ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    try:
        if not LEARNING_DATA_FILE.exists():
            return None, 0.0
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with open(LEARNING_DATA_FILE, 'r') as f:
            data = json.load(f)
        
        if not data['learning_records']:
            return None, 0.0
        
        # ç¾åœ¨ã®ç”»åƒã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
        current_features = extract_image_features(image)
        if not current_features:
            return None, 0.0
        
        # é¡ä¼¼åº¦è¨ˆç®—ã¨ã‚½ãƒ¼ãƒˆ
        similarities = []
        for record in data['learning_records']:
            if not record.get('is_positive_example', True):  # è² ä¾‹ã¯é™¤å¤–
                continue
                
            similarity = calculate_similarity(current_features, record['image_features'])
            
            # æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã®é‡ã¿ä»˜ã‘ï¼ˆ1.2å€ï¼‰
            weight = 1.2 if record.get('is_manual_correction', False) else 1.0
            weighted_similarity = similarity * weight
            
            similarities.append({
                'record': record,
                'similarity': weighted_similarity,
                'confidence': record.get('confidence', 0.5)
            })
        
        if not similarities:
            return None, 0.0
        
        # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        # ç›´è¿‘Nä»¶ã®å¹³å‡å€¤ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
        if use_recent_average and len(similarities) >= 3:
            # ä¸Šä½3ä»¶ã®å¹³å‡ä½ç½®ã‚’è¨ˆç®—
            top_records = similarities[:3]
            avg_x1 = sum(r['record']['band_position'][0] for r in top_records) / len(top_records)
            avg_y1 = sum(r['record']['band_position'][1] for r in top_records) / len(top_records)
            avg_x2 = sum(r['record']['band_position'][2] for r in top_records) / len(top_records)
            avg_y2 = sum(r['record']['band_position'][3] for r in top_records) / len(top_records)
            
            # å¹³å‡é¡ä¼¼åº¦ã‚’è¨ˆç®—
            avg_similarity = sum(r['similarity'] for r in top_records) / len(top_records)
            
            predicted_position = [int(avg_x1), int(avg_y1), int(avg_x2), int(avg_y2)]
            confidence = avg_similarity
        else:
            # æœ€ã‚‚é¡ä¼¼ã—ãŸ1ä»¶ã‚’ä½¿ç”¨
            best_match = similarities[0]
            predicted_position = best_match['record']['band_position']
            confidence = best_match['similarity']
        
        # ä¿¡é ¼åº¦ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹å ´åˆã¯äºˆæ¸¬ã‚’ç„¡åŠ¹ã«ã™ã‚‹
        if confidence < min_confidence:
            return None, confidence
        
        return predicted_position, confidence
    except Exception as e:
        st.error(f"å¸¯ä½ç½®ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, 0.0

def detect_text_regions(image: Image.Image):
    """æ–‡å­—é ˜åŸŸã‚’æ¤œå‡ºï¼ˆOCRãƒ©ã‚¤ã‚¯ãªæ‰‹æ³•ï¼‰"""
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = np.array(image.convert('L'))
        
        # äºŒå€¤åŒ–ï¼ˆæ–‡å­—ã‚’å¼·èª¿ï¼‰
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†ã§æ–‡å­—ã‚’é€£çµ
        kernel = np.ones((2, 2), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        h, w = gray.shape
        
        for cnt in contours:
            x, y, bw, bh = cv2.boundingRect(cnt)
            area = bw * bh
            
            # æ–‡å­—ã‚‰ã—ã„é ˜åŸŸã®æ¡ä»¶
            if (area > 50 and  # æœ€å°ã‚µã‚¤ã‚º
                area < w * h * 0.1 and  # æœ€å¤§ã‚µã‚¤ã‚ºï¼ˆç”»åƒã®10%ä»¥ä¸‹ï¼‰
                bw > 5 and bh > 5 and  # æœ€å°å¹…ãƒ»é«˜ã•
                bw < w * 0.8 and bh < h * 0.3):  # æœ€å¤§å¹…ãƒ»é«˜ã•
                
                text_regions.append((x, y, x + bw, y + bh, area))
        
        return text_regions
    except Exception as e:
        st.error(f"æ–‡å­—é ˜åŸŸæ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

def detect_horizontal_lines(image: Image.Image):
    """æ°´å¹³ç·šã‚’æ¤œå‡º"""
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = np.array(image.convert('L'))
        
        # ã‚¨ãƒƒã‚¸æ¤œå‡º
        edges = cv2.Canny(gray, 50, 150)
        
        # æ°´å¹³ç·šã®æ¤œå‡ºï¼ˆHoughLinesPï¼‰
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=50, maxLineGap=10)
        
        horizontal_lines = []
        h, w = gray.shape
        
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                
                # æ°´å¹³ç·šã®åˆ¤å®šï¼ˆè§’åº¦ãŒ10åº¦ä»¥å†…ï¼‰
                angle = abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
                if angle < 10 or angle > 170:
                    # ç·šã®é•·ã•ãŒç”»åƒå¹…ã®30%ä»¥ä¸Š
                    line_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
                    if line_length > w * 0.3:
                        horizontal_lines.append((x1, y1, x2, y2, line_length))
        
        return horizontal_lines
    except Exception as e:
        st.error(f"æ°´å¹³ç·šæ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

def analyze_background_color(image: Image.Image, region):
    """æŒ‡å®šé ˜åŸŸã®èƒŒæ™¯è‰²ã‚’åˆ†æ"""
    try:
        x1, y1, x2, y2 = region
        region_img = image.crop((x1, y1, x2, y2))
        
        # RGBã«å¤‰æ›
        rgb_img = region_img.convert('RGB')
        np_img = np.array(rgb_img)
        
        # å¹³å‡è‰²ã‚’è¨ˆç®—
        mean_color = np.mean(np_img, axis=(0, 1))
        
        # è‰²ã®ä¸€æ§˜æ€§ã‚’è¨ˆç®—ï¼ˆæ¨™æº–åå·®ãŒå°ã•ã„ã»ã©ä¸€æ§˜ï¼‰
        color_std = np.std(np_img, axis=(0, 1))
        uniformity = 1.0 - (np.mean(color_std) / 255.0)
        
        return {
            'mean_color': mean_color.tolist(),
            'uniformity': float(uniformity),
            'brightness': float(np.mean(mean_color) / 255.0)
        }
    except Exception as e:
        st.error(f"èƒŒæ™¯è‰²åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

def detect_band_by_content(image: Image.Image, reader):
    """ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã¦å¸¯é ˜åŸŸã‚’æ¤œå‡º"""
    try:
        np_img = np.array(image.convert('RGB'))
        h, w, _ = np_img.shape

        # ä¸‹åŠåˆ†ã‚’ã‚¯ãƒ­ãƒƒãƒ—ã—ã¦OCRã®å¯¾è±¡ç¯„å›²ã‚’é™å®š
        scan_area_top = h // 2
        scan_area = np_img[scan_area_top:, :]

        ocr_results = reader.readtext(scan_area, detail=1, paragraph=False)

        # å¸¯ã«ã‚ˆãã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ­£è¦è¡¨ç¾
        keywords = [
            'æ ªå¼ä¼šç¤¾', 'ä¼šç¤¾', 'ä¸€ç´šå»ºç¯‰å£«', 'å…è¨±', 'ç™»éŒ²', 'ä¿è¨¼', 'å”ä¼š',
            'æ‰€åœ¨åœ°', 'ä½æ‰€', 'é›»è©±', 'TEL', 'FAX', 'ãƒ¡ãƒ¼ãƒ«'
        ]
        # æ—¥æœ¬ã®é›»è©±ç•ªå· (ãƒ•ãƒªãƒ¼ãƒ€ã‚¤ãƒ¤ãƒ«å«ã‚€), FAXç•ªå·ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        phone_fax_pattern = re.compile(r'(\d{2,4}-\d{2,4}-\d{4}|\(0\d{1,4}\)\d{1,4}-\d{4}|0120-\d{2,3}-\d{3})')
        
        band_content_boxes = []
        for (bbox, text, prob) in ocr_results:
            if prob < 0.3: continue

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            if any(keyword in text for keyword in keywords):
                band_content_boxes.append(bbox)
                continue
            
            # é›»è©±ç•ªå·ãƒ»FAXç•ªå·æ¤œç´¢
            if phone_fax_pattern.search(text):
                band_content_boxes.append(bbox)

        if not band_content_boxes:
            return None, 0.0

        # æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®Yåº§æ¨™ã®æœ€å°å€¤ï¼ˆå¸¯ã®ä¸Šç«¯å€™è£œï¼‰ã‚’ç‰¹å®š
        min_y_in_scan_area = min([box[0][1] for box in band_content_boxes])
        
        # å…ƒç”»åƒã§ã®çµ¶å¯¾Yåº§æ¨™
        band_top_candidate_y = scan_area_top + min_y_in_scan_area

        # å€™è£œãƒ©ã‚¤ãƒ³ã®ä¸Šéƒ¨ã§æ°´å¹³ç·šã‚’æ¢ã™
        lines = detect_horizontal_lines(image)
        strongest_line_y = 0
        
        # å¸¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å°‘ã—ä¸Šã‹ã‚‰ã€å›³é¢ã®ä¸Šéƒ¨ã«ã‹ã‘ã¦ã®ç¯„å›²ã§ç·šã‚’æ¢ã™
        line_search_top = int(band_top_candidate_y - h * 0.1) 
        line_search_bottom = int(band_top_candidate_y + h * 0.05)
        
        relevant_lines = [
            y1 for x1, y1, x2, y2, length in lines 
            if y1 > line_search_top and y1 < line_search_bottom
        ]

        if relevant_lines:
            # å€™è£œé ˜åŸŸå†…ã§æœ€ã‚‚ä¸‹ã«ã‚ã‚‹ç·šã‚’å¸¯ã®ä¸Šç«¯ã¨ã™ã‚‹
            strongest_line_y = max(relevant_lines)
        
        # ç·šãŒè¦‹ã¤ã‹ã‚Œã°ãã‚Œã‚’ã€ãªã‘ã‚Œã°ãƒ†ã‚­ã‚¹ãƒˆã®é–‹å§‹ä½ç½®ã‚’å¸¯ã®ä¸Šç«¯ã¨ã™ã‚‹
        final_band_top_y = strongest_line_y if strongest_line_y > 0 else band_top_candidate_y
        
        # æœ€çµ‚çš„ãªä¸Šç«¯ä½ç½®ã‚’å¾®èª¿æ•´ï¼ˆå°‘ã—ã ã‘ä¸Šã«ã‚ã’ã‚‹ï¼‰
        final_band_top_y = max(0, final_band_top_y - 10)

        # å¸¯ã®é«˜ã•ãŒå¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
        band_height = h - final_band_top_y
        if not (h * 0.05 < band_height < h * 0.5):
            return None, 0.0 # å¸¯ã®é«˜ã•ãŒ5%æœªæº€ã‹50%ä»¥ä¸Šãªã‚‰ç„¡åŠ¹
        
        score = len(band_content_boxes) / len(ocr_results) if ocr_results else 0.0
        return (0, int(final_band_top_y), w, h), score

    except Exception as e:
        st.error(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã«ã‚ˆã‚‹å¸¯æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, 0.0

def detect_footer_band_by_layout(image: Image.Image):
    """ãƒ•ãƒƒã‚¿ãƒ¼å¸¯ã‚’ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æï¼ˆå‚ç›´ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã§æ¤œå‡º"""
    try:
        gray_img = image.convert('L')
        np_gray = np.array(gray_img)
        h, w = np_gray.shape

        # 1. ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¨ãƒƒã‚¸ã®å‚ç›´æ–¹å‘ã®æŠ•å½±ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        _, binary = cv2.threshold(np_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        text_profile = np.sum(binary, axis=1)

        edges = cv2.Canny(np_gray, 50, 150, apertureSize=3)
        edge_profile = np.sum(edges, axis=1)

        # 2. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£è¦åŒ–ã—ã¦çµåˆ
        if text_profile.max() > 0:
            text_profile = text_profile / text_profile.max()
        if edge_profile.max() > 0:
            edge_profile = edge_profile / edge_profile.max()
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®æ¯”é‡ã‚’é«˜ãã™ã‚‹
        combined_profile = (text_profile * 0.8) + (edge_profile * 0.2)

        # 3. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¹³æ»‘åŒ–ã—ã¦ãƒã‚¤ã‚ºã‚’é™¤å»
        window_size = max(11, int(h * 0.02))
        if window_size % 2 == 0: window_size += 1
        
        if window_size >= len(combined_profile):
             return None, 0.0 # ç”»åƒãŒå°ã•ã™ãã‚‹
        
        smoothed_profile = savgol_filter(combined_profile, window_size, 3) # window, polyorder

        # 4. ç”»åƒä¸‹éƒ¨ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å¸¯ã®ä¸Šç«¯ã‚’æ¢ã™
        scan_start_y = h - 1
        scan_end_y = int(h * 0.5) # ä¸‹åŠåˆ†ã®ã¿ã‚’å¯¾è±¡

        # ç”»åƒä¸‹éƒ¨20%ã®æœ€å¤§å€¤ã‚’åŸºæº–ã¨ã™ã‚‹
        bottom_area_start = int(h * 0.8)
        peak_in_bottom = smoothed_profile[bottom_area_start:].max()

        if peak_in_bottom < 0.1: # ä¸‹éƒ¨ã«ååˆ†ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„å ´åˆã¯å¤±æ•—
            return None, 0.0

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå¤§å¹…ã«æ¸›å°‘ã™ã‚‹ç‚¹ã‚’ã€Œå¸¯ã®ä¸Šç«¯ã€ã¨åˆ¤æ–­
        threshold = peak_in_bottom * 0.35 

        band_top_y = 0
        for y in range(scan_start_y, scan_end_y, -1):
            if smoothed_profile[y] < threshold:
                # å®‰å®šã—ãŸä½ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é ˜åŸŸã‹ç¢ºèª
                rows_to_check = int(h * 0.03) # ç”»åƒé«˜ã•ã®3%ã‚’ãƒã‚§ãƒƒã‚¯
                area_above_y = y - rows_to_check
                if area_above_y < scan_end_y: continue

                if smoothed_profile[area_above_y:y].mean() < threshold * 1.2:
                    band_top_y = y
                    break
        
        if band_top_y == 0: # æ˜ç¢ºãªå¢ƒç•ŒãŒè¦‹ã¤ã‹ã‚‰ãªã„
            return None, 0.0
            
        # 5. æ¤œå‡ºçµæœã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        area_above = smoothed_profile[scan_end_y:band_top_y]
        area_below = smoothed_profile[band_top_y:scan_start_y]
        avg_above = area_above.mean() if len(area_above) > 0 else 0
        avg_below = area_below.mean() if len(area_below) > 0 else 0
        
        # å¸¯éƒ¨åˆ†ã¨ãã‚Œä»¥å¤–ã®éƒ¨åˆ†ã®å·®ãŒå¤§ãã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
        score = (avg_below - avg_above) / (peak_in_bottom + 1e-6)
        
        # æ¤œå‡ºã•ã‚ŒãŸå¸¯ã®é«˜ã•ãŒå¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
        band_height = h - band_top_y
        if not (h * 0.05 < band_height < h * 0.4):
            return None, 0.0 # å¸¯ã®é«˜ã•ãŒ5%æœªæº€ã‹40%ä»¥ä¸Šãªã‚‰ç„¡åŠ¹

        detected_band_region = (0, band_top_y, w, h)
        return detected_band_region, score

    except Exception as e:
        st.error(f"ãƒ•ãƒƒã‚¿ãƒ¼å¸¯ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, 0.0

def auto_detect_drawing_area(image: Image.Image):
    """å›³é¢é ˜åŸŸã‚’è‡ªå‹•æ¤œå‡ºï¼ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æAIï¼‰"""
    h, w = image.height, image.width
    reader = get_ocr_reader()
    if not reader:
        st.error("OCRã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€è‡ªå‹•æ¤œå‡ºã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        return (0, 0, w, int(h*0.8))


    # 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®äºˆæ¸¬ã‚’æœ€å„ªå…ˆ
    predicted_drawing_area, confidence = predict_band_position(image)
    if predicted_drawing_area and confidence > 0.8: # é«˜ä¿¡é ¼åº¦ã®å­¦ç¿’çµæœã‚’å„ªå…ˆ
        st.session_state.recent_predictions.append({
            'position': predicted_drawing_area, 'confidence': confidence, 
            'method': 'learning', 'timestamp': datetime.now().isoformat()
        })
        return predicted_drawing_area

    # 2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã§å¸¯ã‚’æ¤œå‡º
    band_region, content_score = detect_band_by_content(image, reader)
    if band_region and content_score > 0.05: # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ã—ã§ã‚‚ã‚ã‚Œã°æ¡ç”¨
        _, band_top_y, _, _ = band_region
        drawing_area = (0, 0, w, band_top_y)
        
        st.session_state.recent_predictions.append({
            'position': drawing_area, 'confidence': content_score, 
            'method': 'content_analysis', 'timestamp': datetime.now().isoformat()
        })
        return drawing_area
    
    # 3. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
    footer_region, layout_score = detect_footer_band_by_layout(image)
    if footer_region and layout_score > 0.4:
        _, band_top_y, _, _ = footer_region
        drawing_area = (0, 0, w, band_top_y)
        
        st.session_state.recent_predictions.append({
            'position': drawing_area, 'confidence': layout_score, 
            'method': 'layout_analysis_fallback', 'timestamp': datetime.now().isoformat()
        })
        return drawing_area

    # 4. æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    fallback_area = (0, 0, w, int(h * 0.8))
    st.session_state.recent_predictions.append({
        'position': fallback_area, 'confidence': 0.1, 
        'method': 'fallback', 'timestamp': datetime.now().isoformat()
    })
    return fallback_area

def manage_learning_data(max_records=1000):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†ï¼ˆä»¶æ•°åˆ¶é™ã€å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼‰"""
    try:
        if not LEARNING_DATA_FILE.exists():
            return
        
        with open(LEARNING_DATA_FILE, 'r') as f:
            data = json.load(f)
        
        records = data['learning_records']
        
        # ä»¶æ•°åˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        if len(records) > max_records:
            # æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆä¿æŒ
            manual_records = [r for r in records if r.get('is_manual_correction', False)]
            auto_records = [r for r in records if not r.get('is_manual_correction', False)]
            
            # æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦ä¿æŒ
            # è‡ªå‹•æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã¯æ–°ã—ã„é †ã«åˆ¶é™å†…ã¾ã§ä¿æŒ
            keep_auto_count = max_records - len(manual_records)
            if keep_auto_count > 0:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
                auto_records.sort(key=lambda x: x['timestamp'], reverse=True)
                auto_records = auto_records[:keep_auto_count]
            else:
                auto_records = []
            
            # æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆã—ã¦çµåˆ
            records = manual_records + auto_records
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            data['learning_records'] = records
            data['metadata']['total_records'] = len(records)
            data['metadata']['manual_corrections'] = len(manual_records)
            data['metadata']['auto_detections'] = len(auto_records)
            data['metadata']['last_updated'] = datetime.now().isoformat()
            
            # ä¿å­˜
            with open(LEARNING_DATA_FILE, 'w') as f:
                json.dump(data, f, indent=2)
            
            return True
        return False
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def export_learning_data():
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        if not LEARNING_DATA_FILE.exists():
            return None
        
        with open(LEARNING_DATA_FILE, 'r') as f:
            data = json.load(f)
        
        return json.dumps(data, indent=2, ensure_ascii=False)
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

def import_learning_data(import_data):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        data = json.loads(import_data)
        
        # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®æ¤œè¨¼
        if 'learning_records' not in data or 'metadata' not in data:
            st.error("ç„¡åŠ¹ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã™")
            return False
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        if LEARNING_DATA_FILE.exists():
            backup_file = LEARNING_DATA_FILE.with_suffix('.json.backup')
            with open(LEARNING_DATA_FILE, 'r') as f:
                backup_data = f.read()
            with open(backup_file, 'w') as f:
                f.write(backup_data)
        
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        with open(LEARNING_DATA_FILE, 'w') as f:
            json.dump(data, f, indent=2)
        
        st.success("âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        return True
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def clear_learning_data():
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
    try:
        if LEARNING_DATA_FILE.exists():
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
            backup_file = LEARNING_DATA_FILE.with_suffix('.json.backup')
            with open(LEARNING_DATA_FILE, 'r') as f:
                backup_data = f.read()
            with open(backup_file, 'w') as f:
                f.write(backup_data)
            
            # åˆæœŸåŒ–
            init_learning_data()
            st.success("âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆæ¸ˆã¿ï¼‰")
            return True
        return False
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

init_session_state()
init_learning_data()
get_ocr_reader()

@st.cache_data
def load_and_process_image(file_data, file_name):
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«scipyã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯
    try:
        import scipy
    except ImportError:
        st.warning("é«˜ç²¾åº¦ãªå¸¯èªè­˜ï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æï¼‰ã®ãŸã‚ã«ã€SciPyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã€Œpip install scipyã€ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚")
    
    """ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§å‡¦ç†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
    try:
        if file_name.lower().endswith(".pdf"):
            doc = fitz.open(stream=file_data, filetype="pdf")
            page = doc.load_page(0)
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            original_img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            doc.close()
        else:
            original_img = Image.open(io.BytesIO(file_data)).convert("RGB")
        
        # ç”»åƒã‚µã‚¤ã‚ºã®æ¤œè¨¼
        if original_img.width == 0 or original_img.height == 0:
            raise ValueError("ç„¡åŠ¹ãªç”»åƒã‚µã‚¤ã‚ºã§ã™")
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒç”Ÿæˆï¼ˆ800pxå¹…ã«çµ±ä¸€ï¼‰
        PREVIEW_WIDTH = 800
        aspect_ratio = original_img.height / original_img.width
        preview_height = int(PREVIEW_WIDTH * aspect_ratio)
        preview_img = original_img.resize((PREVIEW_WIDTH, preview_height), Image.LANCZOS)
        
        return original_img, preview_img
    except Exception as e:
        st.error(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None, None

def validate_area(area, image_width, image_height):
    """é¸æŠé ˜åŸŸã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not area:
        return False
    
    x1, y1, x2, y2 = area
    
    # åº§æ¨™ãŒæœ‰åŠ¹ãªç¯„å›²å†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if (x1 < 0 or y1 < 0 or x2 > image_width or y2 > image_height):
        return False
    
    # å¹…ã¨é«˜ã•ãŒæ­£ã®å€¤ã‹ãƒã‚§ãƒƒã‚¯
    if x2 <= x1 or y2 <= y1:
        return False
    
    # æœ€å°ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ10pxä»¥ä¸Šï¼‰
    if (x2 - x1) < 10 or (y2 - y1) < 10:
        return False
    
    return True

def find_red_area(template_img: Image.Image):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…ã®èµ¤ã„é ˜åŸŸã‚’æ¤œå‡º"""
    try:
        img = template_img.convert("RGB")
        np_img = np.array(img)
        
        # èµ¤è‰²ã®ç¯„å›²ã‚’HSVã§å®šç¾©ï¼ˆã‚ˆã‚Šæ­£ç¢ºãªæ¤œå‡ºï¼‰
        hsv = cv2.cvtColor(np_img, cv2.COLOR_RGB2HSV)
        
        # èµ¤è‰²ã®ç¯„å›²ï¼ˆHSVï¼‰
        lower_red1 = np.array([0, 120, 120])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([170, 120, 120])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        mask = mask1 + mask2
        
        # è¼ªéƒ­ã‚’æ¤œå‡º
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            # æœ€å¤§ã®èµ¤ã„é ˜åŸŸã‚’å–å¾—
            largest_contour = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest_contour)
            red_area = (x, y, x + w, y + h)
            
            # èµ¤ã„é ˜åŸŸã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if validate_area(red_area, template_img.width, template_img.height):
                return red_area
        
        return None
    except Exception as e:
        st.error(f"èµ¤ã„é ˜åŸŸã®æ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def remove_red_area(template_img: Image.Image, red_area, fill=(255,255,255,255)):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰èµ¤ã„é ˜åŸŸã‚’é™¤å»"""
    try:
        img = template_img.copy().convert("RGBA")
        if red_area:
            x1, y1, x2, y2 = red_area
            # èµ¤ã„é ˜åŸŸã‚’ç™½ã§å¡—ã‚Šã¤ã¶ã—
            draw = ImageDraw.Draw(img)
            draw.rectangle([x1, y1, x2, y2], fill=fill)
        return img
    except Exception as e:
        st.error(f"èµ¤ã„é ˜åŸŸã®é™¤å»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return template_img

def draw_preview_with_area(image: Image.Image, area, color=(255, 0, 0), label="é¸æŠé ˜åŸŸ"):
    """ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã«é¸æŠé ˜åŸŸã‚’æç”»"""
    try:
        img_copy = image.copy()
        draw = ImageDraw.Draw(img_copy)
        
        if area and st.session_state.original_image:
            x1, y1, x2, y2 = area
            # åº§æ¨™ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã«èª¿æ•´
            scale_x = image.width / st.session_state.original_image.width
            scale_y = image.height / st.session_state.original_image.height
            
            px1 = int(x1 * scale_x)
            py1 = int(y1 * scale_y)
            px2 = int(x2 * scale_x)
            py2 = int(y2 * scale_y)
            
            # æ ç·šã‚’æç”»
            draw.rectangle([px1, py1, px2, py2], outline=color, width=3)
            
            # ãƒ©ãƒ™ãƒ«ã‚’æç”»
            try:
                font = ImageFont.truetype("arial.ttf", 16)
            except:
                font = ImageFont.load_default()
            
            draw.text((px1 + 5, py1 + 5), label, fill=color, font=font)
        
        return img_copy
    except Exception as e:
        st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æç”»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return image

def apply_fill_areas(image: Image.Image, fill_areas):
    """è¤‡æ•°ã®å¡—ã‚Šã¤ã¶ã—é ˜åŸŸã‚’é©ç”¨"""
    try:
        result_img = image.copy()
        draw = ImageDraw.Draw(result_img)
        
        for area_info in fill_areas:
            if len(area_info) >= 5:
                x1, y1, x2, y2, color = area_info
                # é ˜åŸŸã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                if validate_area((x1, y1, x2, y2), image.width, image.height):
                    draw.rectangle([x1, y1, x2, y2], fill=color)
        
        return result_img
    except Exception as e:
        st.error(f"å¡—ã‚Šã¤ã¶ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return image

def safe_crop_image(image: Image.Image, area):
    """å®‰å…¨ã«ç”»åƒã‚’ã‚¯ãƒ­ãƒƒãƒ—ã™ã‚‹"""
    try:
        if not validate_area(area, image.width, image.height):
            st.error("ç„¡åŠ¹ãªé¸æŠé ˜åŸŸã§ã™ã€‚ç¯„å›²ã‚’å†é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return None
        
        x1, y1, x2, y2 = area
        cropped = image.crop((x1, y1, x2, y2))
        
        # ã‚¯ãƒ­ãƒƒãƒ—çµæœã®æ¤œè¨¼
        if cropped.width == 0 or cropped.height == 0:
            st.error("ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã®ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚")
            return None
        
        return cropped
    except Exception as e:
        st.error(f"ç”»åƒã®ã‚¯ãƒ­ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def safe_resize_preview(image: Image.Image, target_width):
    """å®‰å…¨ã«ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆ"""
    try:
        if image.width == 0 or image.height == 0:
            st.error("ç„¡åŠ¹ãªç”»åƒã‚µã‚¤ã‚ºã§ã™ã€‚")
            return None
        
        aspect_ratio = image.height / image.width
        preview_height = int(target_width * aspect_ratio)
        
        # æœ€å°ã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
        if preview_height < 1:
            preview_height = 1
        
        preview = image.resize((target_width, preview_height), Image.LANCZOS)
        return preview
    except Exception as e:
        st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def generate_pdf(cropped: Image.Image, template: Image.Image):
    """PDFç”Ÿæˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰"""
    try:
        # å…¥åŠ›ç”»åƒã®æ¤œè¨¼
        if cropped.width == 0 or cropped.height == 0:
            return None, "å‡¦ç†æ¸ˆã¿ç”»åƒã®ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚"
        
        red_area = find_red_area(template)
        if red_area is None:
            return None, "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã«èµ¤ã„é ˜åŸŸãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        x1, y1, x2, y2 = red_area
        area_w, area_h = x2 - x1, y2 - y1
        crop_w, crop_h = cropped.size
        
        # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ã
        if crop_w == 0 or crop_h == 0 or area_w == 0 or area_h == 0:
            return None, "ç”»åƒã¾ãŸã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé ˜åŸŸã®ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚"
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒã—ã¦ãƒªã‚µã‚¤ã‚º
        scale = min(area_w / crop_w, area_h / crop_h)
        new_w = max(1, int(crop_w * scale))
        new_h = max(1, int(crop_h * scale))
        resized_crop = cropped.resize((new_w, new_h), Image.Resampling.LANCZOS)

        # ä¸­å¤®é…ç½®
        paste_x = x1 + (area_w - new_w) // 2
        paste_y = y1 + (area_h - new_h) // 2

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰èµ¤ã„é ˜åŸŸã‚’é™¤å»
        cleared_template = remove_red_area(template, red_area)
        
        # ç”»åƒã‚’åˆæˆ
        combined = cleared_template.copy()
        if resized_crop.mode != 'RGBA':
            resized_crop = resized_crop.convert('RGBA')
        combined.alpha_composite(resized_crop, (paste_x, paste_y))

        # PDFç”Ÿæˆ
        img_buffer = io.BytesIO()
        combined_rgb = combined.convert("RGB")
        combined_rgb.save(img_buffer, format="PNG", dpi=(300, 300))
        img_buffer.seek(0)

        pdf_buffer = io.BytesIO()
        c = canvas.Canvas(pdf_buffer, pagesize=(A4[1], A4[0]))
        c.drawImage(ImageReader(img_buffer), 0, 0, width=A4[1], height=A4[0])
        c.showPage()
        c.save()
        pdf_buffer.seek(0)
        
        return pdf_buffer, "PDFç”ŸæˆæˆåŠŸ"
    
    except Exception as e:
        return None, f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

def generate_filename():
    """ç‰©ä»¶æƒ…å ±ã‚’åŸºã«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
    today = datetime.now().strftime("%y-%m-%d")
    filename_parts = [today]
    
    if st.session_state.property_name:
        filename_parts.append(st.session_state.property_name)
    if st.session_state.property_price:
        filename_parts.append(st.session_state.property_price)
    
    if len(filename_parts) == 1:  # æ—¥ä»˜ã®ã¿ã®å ´åˆ
        filename_parts.append("zumen_output")
    
    return "_".join(filename_parts) + ".pdf"

# ãƒ¡ã‚¤ãƒ³UI
col1, col2 = st.columns(2)

with col1:
    st.header("ğŸ“„ å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«")
    uploaded_pdf = st.file_uploader(
        "å›³é¢PDF ã¾ãŸã¯ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["pdf", "png", "jpg", "jpeg"],
        help="å‡¦ç†ã—ãŸã„å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )

with col2:
    st.header("ğŸ–¼ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒ")
    uploaded_template = st.file_uploader(
        "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒï¼ˆPNGæ¨å¥¨ï¼‰",
        type=["png", "jpg", "jpeg"],
        help="èµ¤ã„å››è§’ãŒæã‹ã‚ŒãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )

# ç‰©ä»¶æƒ…å ±å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.header("ğŸ“ ç‰©ä»¶æƒ…å ±ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰")
col_prop1, col_prop2 = st.columns(2)
with col_prop1:
    property_name = st.text_input("ç‰©ä»¶å", value=st.session_state.property_name, placeholder="ä¾‹ï¼šå±±ç”°ãƒãƒ³ã‚·ãƒ§ãƒ³")
    if property_name != st.session_state.property_name:
        st.session_state.property_name = property_name

with col_prop2:
    property_price = st.text_input("ä¾¡æ ¼", value=st.session_state.property_price, placeholder="ä¾‹ï¼š3980ä¸‡å††")
    if property_price != st.session_state.property_price:
        st.session_state.property_price = property_price

# ãƒ•ã‚¡ã‚¤ãƒ«åãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
if property_name or property_price:
    today = datetime.now().strftime("%y-%m-%d")
    filename_parts = [today]
    if property_name:
        filename_parts.append(property_name)
    if property_price:
        filename_parts.append(property_price)
    preview_filename = "_".join(filename_parts) + ".pdf"
    st.info(f"ğŸ“„ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview_filename}")

if uploaded_pdf and uploaded_template:
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†
    file_changed = (st.session_state.last_uploaded_file != uploaded_pdf.name)
    
    if file_changed or st.session_state.original_image is None:
        with st.spinner("ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            file_data = uploaded_pdf.read()
            original_img, preview_img = load_and_process_image(file_data, uploaded_pdf.name)
            
            if original_img is None or preview_img is None:
                st.error("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            try:
                template_img = Image.open(uploaded_template).convert("RGBA")
                if template_img.width == 0 or template_img.height == 0:
                    st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã®ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚")
                    st.stop()
            except Exception as e:
                st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                st.stop()
            
            st.session_state.original_image = original_img
            st.session_state.preview_image = preview_img
            st.session_state.template_image = template_img
            st.session_state.last_uploaded_file = uploaded_pdf.name
            st.session_state.processing_step = 'auto_detect'
            st.session_state.fill_areas = []
            st.session_state.eyedropper_mode = False
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: è‡ªå‹•å¸¯èªè­˜
    if st.session_state.processing_step == 'auto_detect':
        with st.spinner("å›³é¢é ˜åŸŸã‚’è‡ªå‹•æ¤œå‡ºä¸­..."):
            st.session_state.auto_detected_area = auto_detect_drawing_area(st.session_state.original_image)
            st.session_state.processing_step = 'review_auto'
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: è‡ªå‹•æ¤œå‡ºçµæœã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if st.session_state.processing_step == 'review_auto':
        st.subheader("ğŸ¤– è‡ªå‹•æ¤œå‡ºçµæœ")
        
        # AIäºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚’è¡¨ç¤º
        if st.session_state.recent_predictions:
            latest_prediction = list(st.session_state.recent_predictions)[-1]
            confidence = latest_prediction['confidence']
            
            if confidence > 0.7:
                st.success(f"ğŸ¯ AIä¿¡é ¼åº¦: {confidence:.1%} - é«˜ä¿¡é ¼åº¦ã®äºˆæ¸¬ã§ã™")
            elif confidence > 0.5:
                st.info(f"ğŸ“Š AIä¿¡é ¼åº¦: {confidence:.1%} - ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦ã§ã™")
            else:
                st.warning(f"âš ï¸ AIä¿¡é ¼åº¦: {confidence:.1%} - ä½ä¿¡é ¼åº¦ã§ã™ã€‚æ‰‹å‹•èª¿æ•´ã‚’æ¨å¥¨ã—ã¾ã™")
        
        st.info("ç·‘æ ã®ç¯„å›²ã§ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ")
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã«æ¤œå‡ºé ˜åŸŸã‚’æç”»
        preview_with_area = draw_preview_with_area(
            st.session_state.preview_image, 
            st.session_state.auto_detected_area,
            color=(0, 255, 0),
            label="è‡ªå‹•æ¤œå‡ºã•ã‚ŒãŸå›³é¢é ˜åŸŸ"
        )
        
        st.image(preview_with_area, caption="è‡ªå‹•æ¤œå‡ºçµæœï¼ˆç·‘æ ãŒå›³é¢é ˜åŸŸï¼‰", use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("âœ… ã“ã®é ˜åŸŸã§OK", type="primary"):
                # å›³é¢é ˜åŸŸã‚’ç¢ºå®šã—ã€æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—ã¸
                st.session_state.confirmed_drawing_area = st.session_state.auto_detected_area
                cropped = safe_crop_image(st.session_state.original_image, st.session_state.auto_detected_area)
                if cropped is not None:
                    st.session_state.processed_image = cropped
                    st.session_state.processing_step = 'final'
                    st.rerun()
        
        with col2:
            if st.button("ğŸ”§ æ‰‹å‹•ã§èª¿æ•´"):
                st.session_state.processing_step = 'manual_adjust'
                st.session_state.manual_coords = []
                st.rerun()
        
        with col3:
            if st.button("ğŸ¨ å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰"):
                # å›³é¢é ˜åŸŸã‚’ç¢ºå®šã—ã¦ã‹ã‚‰å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰ã¸
                st.session_state.confirmed_drawing_area = st.session_state.auto_detected_area
                st.session_state.processing_step = 'fill_mode'
                st.session_state.manual_coords = []
                st.rerun()
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: æ‰‹å‹•èª¿æ•´
    elif st.session_state.processing_step == 'manual_adjust':
        st.subheader("ğŸ”§ æ‰‹å‹•ã§å›³é¢é ˜åŸŸã‚’èª¿æ•´")
        st.info("å·¦ä¸Šâ†’å³ä¸‹ã®é †ç•ªã§2ç‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        
        # ã‚¯ãƒªãƒƒã‚¯åº§æ¨™å–å¾—
        coordinates = streamlit_image_coordinates(
            np.array(st.session_state.preview_image),
            key="manual_select"
        )
        
        if coordinates and len(st.session_state.manual_coords) < 2:
            st.session_state.manual_coords.append((coordinates['x'], coordinates['y']))
            if len(st.session_state.manual_coords) == 1:
                st.success("1ç‚¹ç›®ã‚’é¸æŠ")
            else:
                st.success("2ç‚¹ç›®ã‚’é¸æŠ")
        
        # 2ç‚¹ãŒé¸æŠã•ã‚ŒãŸå ´åˆ
        if len(st.session_state.manual_coords) == 2:
            (x1, y1), (x2, y2) = st.session_state.manual_coords
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‹ã‚‰å…ƒç”»åƒã‚µã‚¤ã‚ºã«å¤‰æ›
            scale_x = st.session_state.original_image.width / st.session_state.preview_image.width
            scale_y = st.session_state.original_image.height / st.session_state.preview_image.height
            
            real_x1 = int(min(x1, x2) * scale_x)
            real_y1 = int(min(y1, y2) * scale_y)
            real_x2 = int(max(x1, x2) * scale_x)
            real_y2 = int(max(y1, y2) * scale_y)
            
            manual_area = (real_x1, real_y1, real_x2, real_y2)
            
            # é ˜åŸŸã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if validate_area(manual_area, st.session_state.original_image.width, st.session_state.original_image.height):
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                preview_with_manual = draw_preview_with_area(
                    st.session_state.preview_image,
                    manual_area,
                    color=(255, 0, 0),
                    label="æ‰‹å‹•é¸æŠé ˜åŸŸ"
                )
                st.image(preview_with_manual, caption="æ‰‹å‹•é¸æŠçµæœï¼ˆèµ¤æ ãŒç¢ºå®šã•ã‚Œã‚‹å›³é¢é ˜åŸŸï¼‰", use_container_width=True)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("âœ… ã“ã®é ˜åŸŸã§ç¢ºå®š", type="primary"):
                        # å›³é¢é ˜åŸŸã‚’ç¢ºå®š
                        st.session_state.confirmed_drawing_area = manual_area
                        cropped = safe_crop_image(st.session_state.original_image, manual_area)
                        if cropped is not None:
                            st.session_state.processed_image = cropped
                            st.session_state.processing_step = 'final'
                            st.rerun()
                
                with col2:
                    if st.button("ğŸ¨ å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰"):
                        # å›³é¢é ˜åŸŸã‚’ç¢ºå®šã—ã¦ã‹ã‚‰å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰ã¸
                        st.session_state.confirmed_drawing_area = manual_area
                        st.session_state.processing_step = 'fill_mode'
                        st.session_state.manual_coords = []
                        st.rerun()
                
                with col3:
                    if st.button("ğŸ”„ ã‚„ã‚Šç›´ã—"):
                        st.session_state.manual_coords = []
                        st.rerun()
            else:
                st.error("é¸æŠã•ã‚ŒãŸé ˜åŸŸãŒç„¡åŠ¹ã§ã™ã€‚ã‚‚ã†ä¸€åº¦é¸æŠã—ã¦ãã ã•ã„ã€‚")
                if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
                    st.session_state.manual_coords = []
                    st.rerun()
        
        # æ‰‹å‹•èª¿æ•´æ™‚ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜å‡¦ç†ã‚’è¿½åŠ 
        if st.session_state.processing_step == 'manual_adjust' and len(st.session_state.manual_coords) == 2:
            (x1, y1), (x2, y2) = st.session_state.manual_coords
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‹ã‚‰å…ƒç”»åƒã‚µã‚¤ã‚ºã«å¤‰æ›
            scale_x = st.session_state.original_image.width / st.session_state.preview_image.width
            scale_y = st.session_state.original_image.height / st.session_state.preview_image.height
            
            real_x1 = int(min(x1, x2) * scale_x)
            real_y1 = int(min(y1, y2) * scale_y)
            real_x2 = int(max(x1, x2) * scale_x)
            real_y2 = int(max(y1, y2) * scale_y)
            
            manual_area = (real_x1, real_y1, real_x2, real_y2)
            
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆæ‰‹å‹•ä¿®æ­£ãƒ•ãƒ©ã‚°ä»˜ãï¼‰
            if validate_area(manual_area, st.session_state.original_image.width, st.session_state.original_image.height):
                image_features = extract_image_features(st.session_state.original_image, manual_area)
                if image_features:
                    # æ‰‹å‹•ä¿®æ­£ã¨ã—ã¦é«˜è‡ªä¿¡åº¦ã§ä¿å­˜
                    success = save_learning_data(
                        band_position=manual_area,
                        image_features=image_features,
                        confidence=0.9,  # æ‰‹å‹•ä¿®æ­£ã¯é«˜è‡ªä¿¡åº¦
                        is_manual_correction=True
                    )
                    if success:
                        st.success("âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆæ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é«˜å„ªå…ˆåº¦ã§ç™»éŒ²ï¼‰")
                    else:
                        st.warning("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰
    elif st.session_state.processing_step == 'fill_mode':
        st.subheader("ğŸ¨ å¡—ã‚Šã¤ã¶ã—ãƒ¢ãƒ¼ãƒ‰")
        
        # ç¢ºå®šã•ã‚ŒãŸå›³é¢é ˜åŸŸã‚’è¡¨ç¤º
        if 'confirmed_drawing_area' not in st.session_state:
            st.warning("å›³é¢é ˜åŸŸãŒç¢ºå®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.stop()
        
        dx1, dy1, dx2, dy2 = st.session_state.confirmed_drawing_area
        st.info("ğŸ’¡ æ‰‹é †ï¼šğŸ¨è‰²å–å¾— â†’ ğŸ“ç¯„å›²é¸æŠ â†’ âœ…å®Ÿè¡Œ")
        
        # æ“ä½œãƒ¢ãƒ¼ãƒ‰é¸æŠï¼ˆæ’ä»–çš„ï¼‰
        st.subheader("ğŸ”§ æ“ä½œãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        mode = st.radio(
            "æ“ä½œã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
            ["ğŸ¨ ã‚¹ãƒã‚¤ãƒˆãƒ„ãƒ¼ãƒ«ï¼ˆè‰²å–å¾—ï¼‰", "ğŸ“ ç¯„å›²é¸æŠï¼ˆå¡—ã‚Šã¤ã¶ã—ç¯„å›²æŒ‡å®šï¼‰"],
            index=1 if not st.session_state.eyedropper_mode else 0,
            horizontal=True
        )
        
        # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã®å‡¦ç†
        new_eyedropper_mode = (mode == "ğŸ¨ ã‚¹ãƒã‚¤ãƒˆãƒ„ãƒ¼ãƒ«ï¼ˆè‰²å–å¾—ï¼‰")
        if new_eyedropper_mode != st.session_state.eyedropper_mode:
            st.session_state.eyedropper_mode = new_eyedropper_mode
            st.session_state.manual_coords = []  # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã¯åº§æ¨™ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.rerun()
        
        # ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸèª¬æ˜è¡¨ç¤º
        if st.session_state.eyedropper_mode:
            st.info("ğŸ¨ è‰²ã‚’å–å¾—ã—ãŸã„å ´æ‰€ã‚’ã‚¯ãƒªãƒƒã‚¯")
        else:
            st.info("ğŸ“ å·¦ä¸Šâ†’å³ä¸‹ã®é †ã§å¡—ã‚Šã¤ã¶ã—ç¯„å›²ã‚’ã‚¯ãƒªãƒƒã‚¯")
        
        # å¡—ã‚Šã¤ã¶ã—è‰²é¸æŠ
        # ã‚¹ãƒã‚¤ãƒˆã§å–å¾—ã—ãŸè‰²ãŒã‚ã‚Œã°ä½¿ç”¨ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        default_color = st.session_state.get('selected_color', "#FFFFFF")
        fill_color = st.color_picker("å¡—ã‚Šã¤ã¶ã—è‰²", value=default_color)
        
        # ç¢ºå®šã•ã‚ŒãŸå›³é¢é ˜åŸŸã‚’ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸç”»åƒã§ä½œæ¥­
        drawing_area_image = st.session_state.original_image.crop(st.session_state.confirmed_drawing_area)
        
        # å¡—ã‚Šã¤ã¶ã—æ¸ˆã¿é ˜åŸŸã‚’é©ç”¨
        if st.session_state.fill_areas:
            # å›³é¢é ˜åŸŸå†…ã®ç›¸å¯¾åº§æ¨™ã«å¤‰æ›ã—ã¦å¡—ã‚Šã¤ã¶ã—ã‚’é©ç”¨
            relative_fill_areas = []
            for area in st.session_state.fill_areas:
                fx1, fy1, fx2, fy2, color = area
                # å›³é¢é ˜åŸŸå†…ã®ç›¸å¯¾åº§æ¨™ã«å¤‰æ›
                rel_x1 = fx1 - dx1
                rel_y1 = fy1 - dy1
                rel_x2 = fx2 - dx1
                rel_y2 = fy2 - dy1
                # å›³é¢é ˜åŸŸå†…ã«ã‚¯ãƒªãƒƒãƒ—
                rel_x1 = max(0, min(rel_x1, drawing_area_image.width))
                rel_y1 = max(0, min(rel_y1, drawing_area_image.height))
                rel_x2 = max(0, min(rel_x2, drawing_area_image.width))
                rel_y2 = max(0, min(rel_y2, drawing_area_image.height))
                if rel_x2 > rel_x1 and rel_y2 > rel_y1:
                    relative_fill_areas.append((rel_x1, rel_y1, rel_x2, rel_y2, color))
            
            drawing_area_image = apply_fill_areas(drawing_area_image, relative_fill_areas)
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒç”Ÿæˆ
        current_preview = safe_resize_preview(drawing_area_image, 600)
        if current_preview is None:
            st.error("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.stop()
        
        # æ“ä½œçŠ¶æ³ã®è¡¨ç¤º
        if st.session_state.eyedropper_mode:
            st.write("ğŸ¨ è‰²ã‚’å–å¾—ã™ã‚‹å ´æ‰€ã‚’ã‚¯ãƒªãƒƒã‚¯")
        elif len(st.session_state.manual_coords) == 0:
            st.write("ğŸ“ 1ç‚¹ç›®ï¼ˆå·¦ä¸Šï¼‰ã‚’ã‚¯ãƒªãƒƒã‚¯")
        elif len(st.session_state.manual_coords) == 1:
            st.write("ğŸ“ 2ç‚¹ç›®ï¼ˆå³ä¸‹ï¼‰ã‚’ã‚¯ãƒªãƒƒã‚¯")
        
        # ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªå½¢ã§è¡¨ç¤º
        try:
            coordinates = streamlit_image_coordinates(
                current_preview,
                key=f"image_coords_fill_{len(st.session_state.fill_areas)}"
            )
        except Exception as e:
            st.error(f"ç”»åƒã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            coordinates = None
        
        # åº§æ¨™ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†ï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ¥ã«å®Œå…¨åˆ†é›¢ï¼‰
        if coordinates:
            if st.session_state.eyedropper_mode:
                # ğŸ¨ ã‚¹ãƒã‚¤ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼šè‰²å–å¾—ã®ã¿ï¼ˆåº§æ¨™ã¯ä¸€åˆ‡ä¿å­˜ã—ãªã„ï¼‰
                x, y = coordinates['x'], coordinates['y']
                if 0 <= x < current_preview.width and 0 <= y < current_preview.height:
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‹ã‚‰è‰²ã‚’å–å¾—
                    pixel_color = current_preview.getpixel((x, y))
                    if len(pixel_color) == 3:  # RGB
                        r, g, b = pixel_color
                        hex_color = f"#{r:02x}{g:02x}{b:02x}"
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¦color_pickerã«åæ˜ 
                        st.session_state.selected_color = hex_color
                        st.success(f"è‰²ã‚’å–å¾—: {hex_color}")
                        st.rerun()
            else:
                # ğŸ“ ç¯„å›²é¸æŠãƒ¢ãƒ¼ãƒ‰ï¼šåº§æ¨™ã®ã¿ä¿å­˜ï¼ˆè‰²å–å¾—ã¯è¡Œã‚ãªã„ï¼‰
                if len(st.session_state.manual_coords) < 2:
                    st.session_state.manual_coords.append((coordinates['x'], coordinates['y']))
                    if len(st.session_state.manual_coords) == 1:
                        st.success("1ç‚¹ç›®ã‚’é¸æŠ")
                    else:
                        st.success("2ç‚¹ç›®ã‚’é¸æŠ")
        
        # 2ç‚¹ãŒé¸æŠã•ã‚ŒãŸå ´åˆï¼ˆé€šå¸¸ã®ç¯„å›²é¸æŠãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
        if not st.session_state.eyedropper_mode and len(st.session_state.manual_coords) == 2:
            (x1, y1), (x2, y2) = st.session_state.manual_coords
            
            # å›³é¢é ˜åŸŸå†…ã®åº§æ¨™ã«å¤‰æ›
            scale_x = drawing_area_image.width / current_preview.width
            scale_y = drawing_area_image.height / current_preview.height
            
            rel_x1 = int(min(x1, x2) * scale_x)
            rel_y1 = int(min(y1, y2) * scale_y)
            rel_x2 = int(max(x1, x2) * scale_x)
            rel_y2 = int(max(y1, y2) * scale_y)
            
            # å›³é¢é ˜åŸŸå†…ã§ã‚¯ãƒ©ãƒ³ãƒ—
            rel_x1 = max(0, min(rel_x1, drawing_area_image.width))
            rel_y1 = max(0, min(rel_y1, drawing_area_image.height))
            rel_x2 = max(0, min(rel_x2, drawing_area_image.width))
            rel_y2 = max(0, min(rel_y2, drawing_area_image.height))
            
            # å…ƒç”»åƒã§ã®çµ¶å¯¾åº§æ¨™ã«å¤‰æ›
            abs_x1 = rel_x1 + dx1
            abs_y1 = rel_y1 + dy1
            abs_x2 = rel_x2 + dx1
            abs_y2 = rel_y2 + dy1
            
            # æœ€å°ã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
            if rel_x2 > rel_x1 and rel_y2 > rel_y1 and (rel_x2 - rel_x1) >= 5 and (rel_y2 - rel_y1) >= 5:
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("âœ… å¡—ã‚Šã¤ã¶ã—å®Ÿè¡Œ"):
                        # RGBå€¤ã«å¤‰æ›
                        hex_color = fill_color.lstrip('#')
                        rgb_color = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
                        
                        # çµ¶å¯¾åº§æ¨™ã§ä¿å­˜
                        st.session_state.fill_areas.append((abs_x1, abs_y1, abs_x2, abs_y2, rgb_color))
                        st.session_state.manual_coords = []
                        st.success("å¡—ã‚Šã¤ã¶ã—ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ”„ ç¯„å›²ãƒªã‚»ãƒƒãƒˆ"):
                        st.session_state.manual_coords = []
                        st.rerun()
                
                with col3:
                    if st.button("ğŸ“‹ å¡—ã‚Šã¤ã¶ã—å®Œäº†"):
                        # å›³é¢é ˜åŸŸã‚’ã‚¯ãƒ­ãƒƒãƒ—ã—ã¦å¡—ã‚Šã¤ã¶ã—ã‚’é©ç”¨
                        filled_image = apply_fill_areas(st.session_state.original_image, st.session_state.fill_areas)
                        final_cropped = filled_image.crop(st.session_state.confirmed_drawing_area)
                        st.session_state.processed_image = final_cropped
                        st.session_state.processing_step = 'final'
                        st.rerun()
            else:
                st.error("é¸æŠã•ã‚ŒãŸé ˜åŸŸãŒå°ã•ã™ãã¾ã™ã€‚ã‚ˆã‚Šå¤§ããªç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
                    st.session_state.manual_coords = []
                    st.rerun()
        
        # å¡—ã‚Šã¤ã¶ã—é ˜åŸŸã®ç®¡ç†
        if st.session_state.fill_areas:
            col_mgmt1, col_mgmt2 = st.columns(2)
            with col_mgmt1:
                if st.button("ğŸ—‘ï¸ æœ€å¾Œã®å¡—ã‚Šã¤ã¶ã—ã‚’å‰Šé™¤"):
                    st.session_state.fill_areas.pop()
                    st.rerun()
            
            with col_mgmt2:
                if st.button("ğŸ§¹ å…¨å¡—ã‚Šã¤ã¶ã—ã‚’ã‚¯ãƒªã‚¢"):
                    st.session_state.fill_areas = []
                    st.rerun()
            
            # å¡—ã‚Šã¤ã¶ã—é ˜åŸŸã®ä¸€è¦§è¡¨ç¤º
            with st.expander("å¡—ã‚Šã¤ã¶ã—é ˜åŸŸã®è©³ç´°"):
                for i, area in enumerate(st.session_state.fill_areas):
                    x1, y1, x2, y2, color = area
                    # å›³é¢é ˜åŸŸå†…ã®ç›¸å¯¾åº§æ¨™ã‚‚è¡¨ç¤º
                    rel_x1 = x1 - dx1
                    rel_y1 = y1 - dy1
                    rel_x2 = x2 - dx1
                    rel_y2 = y2 - dy1
                    st.write(f"é ˜åŸŸ {i+1}:")
                    st.write(f"  - å…ƒç”»åƒåº§æ¨™: ({x1}, {y1}) - ({x2}, {y2})")
                    st.write(f"  - å›³é¢å†…åº§æ¨™: ({rel_x1}, {rel_y1}) - ({rel_x2}, {rel_y2})")
                    st.write(f"  - è‰²: RGB{color}")
        
        # ç›´æ¥PDFç”Ÿæˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
        if st.session_state.fill_areas:
            st.subheader("ğŸ“„ PDFç”Ÿæˆ")
            st.info("å¡—ã‚Šã¤ã¶ã—ã‚’é©ç”¨ã—ãŸçŠ¶æ…‹ã§PDFã‚’ç”Ÿæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
            
            # PDFç”Ÿæˆå‡¦ç†ã‚’è‡ªå‹•å®Ÿè¡Œ
            with st.spinner("PDFã‚’ç”Ÿæˆä¸­..."):
                # å¡—ã‚Šã¤ã¶ã—ã‚’é©ç”¨ã—ã¦ã‹ã‚‰å›³é¢é ˜åŸŸã§åˆ‡ã‚ŠæŠœã
                filled_image = apply_fill_areas(st.session_state.original_image, st.session_state.fill_areas)
                current_filled_image = filled_image.crop(st.session_state.confirmed_drawing_area)
                pdf_buffer, message = generate_pdf(current_filled_image, st.session_state.template_image)
                
                if pdf_buffer:
                    st.success("âœ… PDFç”Ÿæˆå®Œäº†ï¼ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                    st.download_button(
                        "ğŸ“¥ å¡—ã‚Šã¤ã¶ã—çŠ¶æ…‹ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=pdf_buffer.getvalue(),
                        file_name=generate_filename(),
                        mime="application/pdf",
                        type="primary",
                        use_container_width=True
                    )
                else:
                    st.error(message)
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: æœ€çµ‚ç¢ºèªã¨PDFç”Ÿæˆ
    elif st.session_state.processing_step == 'final':
        st.subheader("ğŸ“„ æœ€çµ‚ç¢ºèªã¨PDFç”Ÿæˆ")
        
        # å‡¦ç†æ¸ˆã¿ç”»åƒã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if st.session_state.processed_image:
            # å®‰å…¨ãªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
            final_preview = safe_resize_preview(st.session_state.processed_image, 600)
            
            if final_preview is not None:
                st.image(final_preview, caption="å‡¦ç†æ¸ˆã¿å›³é¢ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åˆæˆã•ã‚Œã‚‹éƒ¨åˆ†ï¼‰", use_container_width=True)
                
                # PDFç”Ÿæˆå‡¦ç†ã‚’è‡ªå‹•å®Ÿè¡Œ
                with st.spinner("PDFã‚’ç”Ÿæˆä¸­..."):
                    pdf_buffer, message = generate_pdf(st.session_state.processed_image, st.session_state.template_image)
                    
                    if pdf_buffer:
                        st.success("âœ… PDFç”Ÿæˆå®Œäº†ï¼ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.download_button(
                                "ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=pdf_buffer.getvalue(),
                                file_name=generate_filename(),
                                mime="application/pdf",
                                type="primary",
                                use_container_width=True
                            )
                        
                        with col2:
                            if st.button("ğŸ”™ æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—", use_container_width=True):
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
                                for key in ['processed_image', 'processing_step', 'manual_coords', 'fill_areas', 'auto_detected_area', 'confirmed_drawing_area', 'eyedropper_mode']:
                                    if key in st.session_state:
                                        del st.session_state[key]
                                st.session_state.processing_step = 'auto_detect'
                                st.rerun()
                    else:
                        st.error(message)
            else:
                st.error("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
                if st.button("ğŸ”™ æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—"):
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
                    for key in ['processed_image', 'processing_step', 'manual_coords', 'fill_areas', 'auto_detected_area', 'confirmed_drawing_area', 'eyedropper_mode']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.session_state.processing_step = 'auto_detect'
                    st.rerun()

elif uploaded_pdf:
    st.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒï¼ˆPNGï¼‰ã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
elif uploaded_template:
    st.info("å›³é¢PDF ã¾ãŸã¯ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
else:
    st.info("å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«æ“ä½œã‚¬ã‚¤ãƒ‰
with st.sidebar:
    st.header("ğŸ“– æ“ä½œã‚¬ã‚¤ãƒ‰")
    st.markdown("""
    ### ğŸš€ ä½¿ã„æ–¹
    1. **å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«**ã¨**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”»åƒ**ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    2. **è‡ªå‹•æ¤œå‡ºçµæœ**ã‚’ç¢ºèª
    3. å¿…è¦ã«å¿œã˜ã¦**æ‰‹å‹•èª¿æ•´**ã¾ãŸã¯**å¡—ã‚Šã¤ã¶ã—**
    4. **PDFç”Ÿæˆ**ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    ### âœ¨ æ–°æ©Ÿèƒ½ v1.7.4 - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æAI
    - ğŸ¤– **OCRæ­è¼‰**: å›³é¢ä¸‹éƒ¨ã®æ–‡å­—ã‚’ç›´æ¥èª­ã¿å–ã‚Šã€å†…å®¹ã‚’ç†è§£
    - ğŸ” **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º**: ã€Œæ ªå¼ä¼šç¤¾ã€ã€Œé›»è©±ç•ªå·ã€ã€Œå…è¨±ç•ªå·ã€ãªã©å¸¯ç‰¹æœ‰ã®æƒ…å ±ã‚’è‡ªå‹•ã§ç™ºè¦‹
    - ğŸ¯ **æƒ…å ±ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: é–¢é€£æƒ…å ±ãŒå¯†é›†ã™ã‚‹é ˜åŸŸã‚’ã€Œå¸¯ã€ã¨ã—ã¦ç‰¹å®š
    - ğŸ“ **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æ**: ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¨ã€ãã‚Œã‚’åŒºåˆ‡ã‚‹æ°´å¹³ç·šã‚’çµ„ã¿åˆã‚ã›ã€å¸¯ã®ä¸Šç«¯ã‚’æ­£ç¢ºã«æ±ºå®š
    - ğŸ§  **3æ®µéšæ¤œå‡º**: å­¦ç¿’â†’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æâ†’ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã®é †ã§é«˜ç²¾åº¦ã«æ¤œå‡º
    
    ### ğŸ”§ æŠ€è¡“çš„æ”¹å–„
    - **EasyOCR**: é«˜ç²¾åº¦ãªæ—¥æœ¬èªOCRãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å°å…¥
    - **æ­£è¦è¡¨ç¾**: é›»è©±ç•ªå·ãªã©ã®è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºå®Ÿã«æŠ½å‡º
    - **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æã§å¯¾å¿œ
    """)
    
    if st.session_state.get('processing_step'):
        st.info(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: {st.session_state.processing_step}")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºç”¨ï¼‰
    if st.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º"):
        st.write("### ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
        if st.session_state.original_image:
            st.write(f"å…ƒç”»åƒã‚µã‚¤ã‚º: {st.session_state.original_image.width} x {st.session_state.original_image.height}")
        if st.session_state.processed_image:
            st.write(f"å‡¦ç†æ¸ˆã¿ç”»åƒã‚µã‚¤ã‚º: {st.session_state.processed_image.width} x {st.session_state.processed_image.height}")
        st.write(f"å¡—ã‚Šã¤ã¶ã—é ˜åŸŸæ•°: {len(st.session_state.fill_areas)}")
        if st.session_state.auto_detected_area:
            st.write(f"è‡ªå‹•æ¤œå‡ºé ˜åŸŸ: {st.session_state.auto_detected_area}")
        if 'confirmed_drawing_area' in st.session_state:
            st.write(f"ç¢ºå®šå›³é¢é ˜åŸŸ: {st.session_state.confirmed_drawing_area}")
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±
        if LEARNING_DATA_FILE.exists():
            try:
                with open(LEARNING_DATA_FILE, 'r') as f:
                    data = json.load(f)
                st.write("### ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
                st.write(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {data['metadata']['total_records']}")
                st.write(f"æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿: {data['metadata']['manual_corrections']}")
                st.write(f"è‡ªå‹•æ¤œå‡ºãƒ‡ãƒ¼ã‚¿: {data['metadata']['auto_detections']}")
                st.write(f"æœ€çµ‚æ›´æ–°: {data['metadata']['last_updated']}")
                st.write(f"ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {data.get('version', '1.0')}")
            except Exception as e:
                st.write(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # äºˆæ¸¬å±¥æ­´
        if st.session_state.recent_predictions:
            st.write("### ğŸ”„ äºˆæ¸¬å±¥æ­´ï¼ˆç›´è¿‘10ä»¶ï¼‰")
            # `list()`ã§dequeã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ã‹ã‚‰é€†é †ã«ã™ã‚‹
            for i, pred in enumerate(reversed(list(st.session_state.recent_predictions)[-5:])):  # æœ€æ–°5ä»¶ã®ã¿è¡¨ç¤º
                method = pred.get('method', 'unknown')
                method_emoji = {
                    'learning': 'ğŸ§ ',
                    'content_analysis': 'ğŸ¤–',
                    'layout_analysis_fallback': 'ğŸ“Š',
                    'fallback': 'ğŸ”„'
                }.get(method, 'â“')
                st.write(f"äºˆæ¸¬ {i+1}: {method_emoji} {method} - ä¿¡é ¼åº¦ {pred.get('confidence', 0):.3f}")
        
        # æ¤œå‡ºæ–¹æ³•ã®è©³ç´°æƒ…å ±
        if st.session_state.recent_predictions:
            latest_prediction = list(st.session_state.recent_predictions)[-1]
            method = latest_prediction.get('method', 'unknown')
            
            st.write("### ğŸ” æœ€æ–°æ¤œå‡ºè©³ç´°")
            if method == 'learning':
                st.info("ğŸ§  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’ä½¿ç”¨")
            elif method == 'content_analysis':
                st.success("ğŸ¤– ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æAIã«ã‚ˆã‚‹æ¤œå‡ºã‚’ä½¿ç”¨")
            elif method == 'layout_analysis_fallback':
                st.warning("ğŸ“Š ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†æï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã‚’ä½¿ç”¨")
            elif method == 'fallback':
                st.warning("ğŸ”„ æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨")
            
            # ç‰¹å¾´ãƒ™ãƒ¼ã‚¹æ¤œå‡ºã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
            if method == 'feature_based' and st.session_state.original_image:
                st.write("#### ğŸ“Š ç‰¹å¾´åˆ†æçµæœ")
                try:
                    # æ–‡å­—é ˜åŸŸã¨æ°´å¹³ç·šã‚’å†æ¤œå‡ºã—ã¦è¡¨ç¤º
                    text_regions = detect_text_regions(st.session_state.original_image)
                    horizontal_lines = detect_horizontal_lines(st.session_state.original_image)
                    
                    st.write(f"æ¤œå‡ºã•ã‚ŒãŸæ–‡å­—é ˜åŸŸæ•°: {len(text_regions)}")
                    st.write(f"æ¤œå‡ºã•ã‚ŒãŸæ°´å¹³ç·šæ•°: {len(horizontal_lines)}")
                    
                    if text_regions:
                        st.write("æ–‡å­—å¯†åº¦ã®é«˜ã„é ˜åŸŸã‚’æ¤œå‡º")
                    if horizontal_lines:
                        st.write("åŒºåˆ‡ã‚Šç·šã‚’æ¤œå‡º")
                        
                except Exception as e:
                    st.write(f"ç‰¹å¾´åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("ğŸ—„ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
    
    # ç¾åœ¨ã®å­¦ç¿’ä»¶æ•°ã‚’è¡¨ç¤º
    if LEARNING_DATA_FILE.exists():
        try:
            with open(LEARNING_DATA_FILE, 'r') as f:
                data = json.load(f)
            metadata = data.get('metadata', {})
            total = metadata.get('total_records', 0)
            manual = metadata.get('manual_corrections', 0)
            auto = metadata.get('auto_detections', 0)
            st.info(f"**ç·å­¦ç¿’æ•°: {total}ä»¶**\n- æ‰‹å‹•ä¿®æ­£: {manual}ä»¶\n- è‡ªå‹•æ¤œå‡º: {auto}ä»¶")
        except (json.JSONDecodeError, KeyError):
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã€ã¾ãŸã¯ç ´æã—ã¦ã„ã‚‹å ´åˆ
            st.warning("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä»¶æ•°ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®èª¬æ˜
    st.markdown("""
    ### ğŸ“‹ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦
    - **ä¿å­˜ä»¶æ•°**: ç†è«–ä¸Šç„¡åˆ¶é™ï¼ˆæ¨å¥¨: 1,000ä»¶ç¨‹åº¦ï¼‰
    - **æ°¸ç¶šæ€§**: ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ã‚‚ä¿æŒã•ã‚Œã¾ã™
    - **è‡ªå‹•åæ˜ **: æ‰‹å‹•èª¿æ•´æ™‚ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å­¦ç¿’
    - **å„ªå…ˆåº¦**: æ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã¯é«˜å„ªå…ˆåº¦ã§ç®¡ç†
    """)
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒœã‚¿ãƒ³
    col_mgmt1, col_mgmt2 = st.columns(2)
    
    with col_mgmt1:
        if st.button("ğŸ“¤ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
            export_data = export_learning_data()
            if export_data:
                st.download_button(
                    "ğŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=export_data,
                    file_name=f"learning_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
    
    with col_mgmt2:
        if st.button("ğŸ—‘ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
            if clear_learning_data():
                st.rerun()
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    st.subheader("ğŸ“¥ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    uploaded_learning_data = st.file_uploader(
        "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["json"],
        help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã™"
    )
    
    if uploaded_learning_data:
        try:
            import_data = uploaded_learning_data.read().decode('utf-8')
            if st.button("âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ"):
                if import_learning_data(import_data):
                    # scipyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä¿ƒã™
                    try:
                        import scipy
                    except ImportError:
                        st.warning("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåˆ†ææ©Ÿèƒ½ã«ã¯SciPyãŒå¿…è¦ã§ã™ã€‚`pip install scipy`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    
                    # easyocrã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ä¿ƒã™
                    try:
                        import easyocr
                    except ImportError:
                        st.warning("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†ææ©Ÿèƒ½ã«ã¯EasyOCRãŒå¿…è¦ã§ã™ã€‚`pip install easyocr`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                    st.rerun()
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¶æ•°åˆ¶é™è¨­å®š
    st.subheader("âš™ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è¨­å®š")
    max_records = st.slider(
        "æœ€å¤§ä¿å­˜ä»¶æ•°",
        min_value=100,
        max_value=5000,
        value=1000,
        step=100,
        help="ã“ã®ä»¶æ•°ã‚’è¶…ãˆã‚‹ã¨å¤ã„è‡ªå‹•æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã™ï¼ˆæ‰‹å‹•ä¿®æ­£ãƒ‡ãƒ¼ã‚¿ã¯å„ªå…ˆä¿æŒï¼‰"
    )
    
    if st.button("ğŸ”§ ä»¶æ•°åˆ¶é™ã‚’é©ç”¨"):
        if manage_learning_data(max_records):
            st.success(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’{max_records}ä»¶ã«åˆ¶é™ã—ã¾ã—ãŸ")
            st.rerun()
        else:
            st.info("â„¹ï¸ ç¾åœ¨ã®ä»¶æ•°ã¯åˆ¶é™å†…ã§ã™")